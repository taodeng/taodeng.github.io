
<!--<link rel="stylesheet" href="jemdoc.css" type="text/css" />-->
<link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.min.css">

<title>Tao Deng</title>

</head>
<body>

<!-- Project
<div class="menu"> <a href="#home">Home</a> 
<a href="#publications">Publications</a> 
<a href="#services">Services</a> 
<a href="#awards">Awards</a>  
</div>
 -->
 
<a id="home" class="anchor"></a>
<div id="container"> 
<div class="container"> 
<!--
<div id="toptitle">
<h1>Kai-Fu Yang</h1>
</div>
 -->

<table class="imgtable"><tr><td>
<a href="./"><img src="./pics/deng.jpeg" alt="" height="240px" /></a>&nbsp;</td>
<td align="left"><p><font size="5">Tao Deng (邓涛)</font> <br />
Assistant Professor <br />
Visual cognition and computing, Visual attention mechanism, Computer vision, Intelligent transportation  <br />
视觉认知计算、视觉注意机制、计算机视觉、智能交通<br />
<br />
<a href="https://www.swjtu.edu.cn/">School of Information Science and Technology</a><br />
Southwest Jiaotong University<br />
No. 999, Xi'an Road, Pidu District, Chengdu, Sichuan, 611756, P. R. China.<br />
<br />
Email:tdeng [AT] swjtu.edu.cn, tinydao [AT] 163.com <br />
[<a class="p" href="https://scholar.google.com.hk/citations?user=WQ2hfUYAAAAJ&hl=en" target="_blank">Google Scholar</a>]</p>
</td></tr></table>

<h2>About Me</h2>
<p> I received the B.S. degree and Ph.D. degree in <a class="p" href="https://www.neuro.uestc.edu.cn/vccl/home.html" target="_blank">Center for Visual Cognition and Brain-Inspired Computation (ViCBiC)</a>,
    MOE Key Lab for Neuroinformation, School of Life Science and Technology, University of Electronic Science and Technology of China(UESTC) in 2018.
    I was a visiting PhD from Oct. 2016 to Oct. 2017 in <a class="p" href="https://vision.ece.ucsb.edu/" target="_blank">Vision Research Lab</a>, Department of Electrical and Computer Engineering, University of California Santa Barbara (UCSB), CA.<br />
    Now I am with School of Information Science and Technology, Southwest Jiaotong University.
    My current research interests include human visual attention modeling (including bottom-up and top-down), eye tracking, saliency detection, computer vision, deep learning, image/video processing, traffic driving scene visual prediction model, intelligent transportation.
</p>

<h2>Research Interests</h2>
Human visual attention modeling (including bottom-up and top-down), eye tracking, saliency detection, computer vision, deep learning, image/video processing,
    traffic driving scene visual prediction model, intelligent transportation.I conduct interdisciplinary research at the intersection of visual cognition and computer vision.
My research aims to explore the underlying computational theory of visual cognition and develop bio-inspired methods for computer vision applications.<br />
<br />
Recent research topics:
<li> Visual attention & understranding in traffic driving scenes</li>
<li> Computer vision in traffic scenes</li>
<li> Medical image processing</li>

<h2>Employment</h2>
    <p><font size="4">2018.09--now</font> <br />
Assistant Professor, School of Information Science and Technology, Southwest Jiaotong University, Chengdu, China.

<h2>Educations</h2>
    <p><font size="4">2012.09--2018.06 </font> <br />
M.S. & Ph.D. program in Visual attention, Vision computation, Computer Vision, Saliency detection, Intelligent transportation <br />

Center for Visual Cognition and Brain-Inspired Computation (ViCBiC), Key Laboratory for Neuroinformation of the Ministry of Education, University of Electronic Science and Technology of China(UESTC), Chengdu, China (superadvisor: Hongmei Yan) <br />

<p><font size="4">2008.09--2012.07 </font><br />
B.S. in Information and Computing Science Department of Mathematics and Computer Science, Hunan University of Science and Technology <br />

<h2>Professional Activities</h2>
   IEEE, CCF, CAA, CAAI Member  <br />

   Reviewer for IEEE T-IP, IEEE Trans. Intelligent Transportation Systems, IEEE Trans. Multimedia, IEEE Intelligent Transportation Systems Magazine, IEEE ITSC <br />

    
<!--<h2>News</h2>-->
<!--<ul>-->
<!--<li> XXXX.</li>-->
<!--</ul>-->

<!-- Project -->
<a id="projects" class="anchor"></a>
<h2>Projects and Publications</h2>

<table class="imgtable">
	
	
<!--Adaptation-->
<tr>
<td><img class="proj_thumb" src="./pics/SDTD.png" alt="" height="180px"/>&nbsp;</td>
<td>
<p class="pub_title">Visual Attention in Traffic Driving </p>
<font size="2.5">
<li>Han Tian, <b>Tao Deng*</b>, and Hongmei Yan. Driving as well as on a Sunny Day? Predicting Driver's Fixation in Rainy Weather Conditions via a Dual-branch Visual Model. <b><i>IEEE/CAA Journal of Automatica Sinica</i></b>, 2022. </li>
<li>Long Qin, Yi Shi, Yahui He, Junrui Zhang, Xianshi Zhang, Yongjie Li, <b>Tao Deng*</b> and Hongmei Yan*. ID-YOLO: Real-Time Salient Object Detection Based on the Driver's Fixation Region. <b><i>IEEE Transactions on Intelligent Transportation Systems (TITS)</i></b>, 2022. DOI: 10.1109/TITS.2022.3146271.  </li>
    <li>Shihui Ji, <b>Tao Deng*</b>, Fei Yan, and Pengcheng Du. A Driving Position-Sensitive Neural Network for Driver Fixation Prediction. <b><i> The 41st Chinese Control Conference</i></b> , 2022. </li>
    <li> <b>Tao Deng*</b>, Fei Yan, Hongmei Yan. Driving Video Fixation Prediction Model via Spatio-Temporal Networks and Attention Gates. <b><i>IEEE International Conference on Multimedia and Expo (ICME)</i></b>, 2021, pp. 1-6, DOI: 10.1109/ICME51207.2021.9428151.</li>
    <li><b>Tao Deng</b>, Hongmei Yan*, Long Qin, Thuyen Ngo, B.S. Manjunath. How Do Drivers Allocate Their Potential Attention? Driving Fixation Prediction via Convolutional Neural Networks. <b><i>IEEE Transactions on Intelligent Transportation Systems</i></b>. 21(5): 2146-2154, 2020. </li>
<li><b>Tao Deng</b>, Hongmei Yan*, Yong-Jie Li*. Learning to Boost Bottom-Up Fixation Prediction in Driving Environments via Random Forest. <b><i>IEEE Transactions on Intelligent Transportation Systems</i></b>, 19(9):3059-3067, 2018. [PDF] [Dataset] </li>
<li><b>Tao Deng</b>, Kaifu Yang, Yong-Jie Li, Hongmei Yan*. Where does the driver look? Top-down based saliency detection in a traffic driving environment. <b><i>IEEE Transactions on Intelligent Transportation Systems</i></b>, 17 (7), 2051 - 2062, 2016. [PDF] [Code & data] </li>
<li><b>Tao Deng</b>, Andong Chen, Min Gao, Hongmei Yan*. Top-down based saliency model in traffic driving environment. <i>IEEE 17th International Conference on Intelligent Transportation Systems (ITSC)</i></b>, 2014: 75-80. [PDF] </li>
    <li><b>Tao Deng</b>, Enqing Luo, Yanshan Zhang, and Hongmei Yan*, Selective attention based saliency of traffic images and characteristics of eye movement. <b><i>Journal of University of Electronic Science and Technology of China</i></b>, 2014, vol. 43, no. 4, pp. 624–628. [PDF] </li>


</font>
</p> </td>
</tr>
	
	
<!--Attention-->
<tr>
<td><img class="proj_thumb" src="./pics/lane.png" alt="" height="100px"/>&nbsp;</td>
<td>
<p class="pub_title">Computer Vision in Traffic Scene</p>
<font size="2.5">
    <li>Jiyong Zhang, <b>Tao Deng*</b>, and Fei Yan. TARConvGRU: A Cross-dimension Spatiotemporal Model for Lane Detection. <b><i>International Joint Conference on Neural Networks</i></b>, 2022. </li>
    <li>Jiyong Zhang, <b>Tao Deng*</b>, Fei Yan and Wenbo Liu. DRSTNet: A Robust Spatio-temporal Network with Dilated Residual Convolutions for Lane Detection. <b><i>2021 5th International Conference on Vision, Image and Signal Processing (ICVISP)</i></b>, IEEE, 2021: 49-54. </li>
    <li>Jiyong Zhang, Fei Yan, Wenbo Liu, and <b>Tao Deng</b>. A Robust Lane Detection Model via Vertical Spatial Convolutions. <b><i>IEEE International Intelligent Transportation Systems Conference (ITSC)</i></b>, 2021: 2835-2840. </li>
    <li>Jiyong Zhang, <b>Tao Deng*</b>, Fei Yan, Wenbo Liu; Lane Detection Model Based on Spatio-Temporal Network with Double Convolutional Gated Recurrent Units, <b><i>IEEE Transactions on Intelligent Transportation Systems</i></b>, 2021, DOI: 10.1109/TITS.2021.3060258. [Link] </li>
    <li>Wenbo Liu, Fei Yan, Jiyong Zhang, <b>Tao Deng*</b>. A Robust Lane Detection Model Using Vertical Spatial Features and Contextual Driving Information. <b><i>Sensors</i></b>, 21(3), 708, 2021. [Link] </li>
    <li>Wenbo Liu, Fei Yan, Kuan Tang, and <b>Tao Deng</b>. Lane detection in complex scenes based on end-to-end neural network. <b><i>2020 Chinese Automation Congress (CAC)</i></b>. IEEE, 2020: 4300-4305. </li>
</font>
</p> </td>
</tr>


	
<!--Ophthalmic-->
<tr>
<td><img class="proj_thumb" src="./pics/MIP.png" alt="" height="120px"/>&nbsp;</td>
<td>
<p class="pub_title">Medical Image Processing</p>
<font size="2.5">
    <li> <b>Tao Deng*</b>, Yi Huang, and Junfeng Zhang. MLFF: Multiple Low-level Features Fusion Model for Retinal Vessel Segmentation. <b><i>International Conference on Bio-Inspired Computing: Theories and Applications (BIC-TA)</i></b>. Springer, Singapore, 2021: 271-281.</li>
</font>
</p> </td>
</tr>

</table> 


<div id="footer">
<div id="footer-text">

</div>
</div>
</body>
</html>
